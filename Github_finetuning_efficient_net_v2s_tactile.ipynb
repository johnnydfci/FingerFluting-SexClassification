{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEy3twDT7p1Y"
   },
   "source": [
    "####**Exploring train dataset** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "SqJYlEhzllaO",
    "outputId": "0ed19ff8-dc77-494a-c994-08f779369390"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        n = 0\n",
    "        for f in files:\n",
    "            n = n+1\n",
    "            if n>5:\n",
    "                print('{}{}'.format(subindent, f),end = \"  ...... \\n\")\n",
    "                break\n",
    "            print('{}{}'.format(subindent, f))\n",
    "\n",
    "img_dir = 'tactile_img/'\n",
    "list_files(\"tactile_img/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "6PKJoktM5gSl",
    "outputId": "1b4bc527-31f1-4b1b-d135-7b9d5f790df3"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH_TRAIN =  os.path.join(img_dir, 'TRAIN')\n",
    "\n",
    "PATH_TEST = os.path.join(img_dir, 'TEST')\n",
    "\n",
    "normal_sample = cv2.imread(PATH_TRAIN+\"/FEMALE/\"+os.listdir(PATH_TRAIN+\"/FEMALE\")[3])\n",
    "infected_sample = cv2.imread(PATH_TRAIN+\"/MALE/\"+os.listdir(PATH_TRAIN+\"/MALE\")[2])\n",
    "\n",
    "plt.imshow(normal_sample)\n",
    "plt.title(\"FEMALE\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(infected_sample)\n",
    "plt.title(\"MALE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPyyju3b26XY"
   },
   "source": [
    "The difference can be seen with different visualizations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P76BSNmx2ASA",
    "outputId": "ff0f4af5-bdf1-4ba4-def1-15f56cb0755c"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(normal_sample)\n",
    "plt.title(\"FEMALE\")\n",
    "plt.show()\n",
    "\n",
    "image = io.imread(PATH_TRAIN+\"/FEMALE/\"+os.listdir(PATH_TRAIN+\"/FEMALE\")[3])\n",
    "ax = plt.hist(image.ravel(), bins = 256)\n",
    "plt.xlabel('Intensity Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(infected_sample)\n",
    "plt.title(\"MALE\")\n",
    "plt.show()\n",
    "\n",
    "image = io.imread(PATH_TRAIN+\"/MALE/\"+os.listdir(PATH_TRAIN+\"/MALE\")[2])\n",
    "ax = plt.hist(image.ravel(), bins = 256)\n",
    "plt.xlabel('Intensity Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSL-YrE3cHC0"
   },
   "source": [
    "####**Initializing the data loader** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocMttMCk2_G6"
   },
   "source": [
    "vgg16 pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224.<br />\n",
    "The images have to be loaded in to a range of [0, 1] and then normalized using:\n",
    " #### mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225] <br />\n",
    " \n",
    " We are applying augmentation like random rotation , horizontal and vertical flips to make sre the model doesn't overfit or learn the wrong features\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ro55AsGYF8v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import torchvision\n",
    "from PIL import ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# ghf\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # To prevent error during loading broken images\n",
    "\n",
    "PATH_TRAIN =  os.path.join(img_dir, 'TRAIN')\n",
    "PATH_TEST = os.path.join(img_dir, 'TEST')\n",
    "\n",
    "# NOW TEST is a validation set.\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "TOTAL_SIZE = len(os.listdir(PATH_TRAIN + \"/FEMALE\")) + len(\n",
    "    os.listdir(PATH_TRAIN + \"/MALE\")\n",
    ")\n",
    "TOTAL_TEST_SIZE = len(os.listdir(PATH_TEST + \"/FEMALE\")) + len(\n",
    "    os.listdir(PATH_TEST + \"/MALE\")\n",
    ")\n",
    "STEPS_PER_EPOCH = TOTAL_SIZE // BATCH_SIZE\n",
    "STEPS_PER_TEST_EPOCH = TOTAL_TEST_SIZE // BATCH_SIZE\n",
    "IMAGE_H, IMAGE_W = 224, 224\n",
    "\n",
    "print(TOTAL_SIZE , TOTAL_TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DNcfdFSckFP"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),                  # Resize input images to a uniform size\n",
    "    transforms.RandomRotation(degrees=(-10, 10)),   # Randomly rotate the image between -10 and 10 degrees\n",
    "    transforms.RandomHorizontalFlip(p=0.5),         # Random horizontal flip with a probability of 0.5\n",
    "    transforms.RandomVerticalFlip(p=0.5),           # Random vertical flip with a probability of 0.5\n",
    "    transforms.RandomPerspective(distortion_scale=0.6, p=1.0),    # Apply random perspective transformation\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),  # Apply Gaussian blur with randomly chosen parameters\n",
    "    transforms.ToTensor(),          # Convert PIL Image or numpy.ndarray to tensor and scale to [0, 1]\n",
    "    transforms.Normalize(           # Normalize to a standard Gaussian distribution to help the model converge faster\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225])   # Mean and std values are computed from a sample of the dataset\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Intitalizing the train data loader and applying the transformations\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=PATH_TRAIN, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=True\n",
    ")\n",
    "\n",
    "# Intitalizing the test data loader\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=PATH_TEST, transform=transform\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.efficientnet import EfficientNet_V2_S_Weights\n",
    "\n",
    "\n",
    "model_ft = torchvision.models.efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT,\n",
    "                                                progress=True)  # Initializing weight\n",
    "\n",
    "# fggffg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 \n",
    "#     and may be removed in the future. \n",
    "# The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. \n",
    "# You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
    "\n",
    "\n",
    "num_ftrs = model_ft.classifier[1].in_features # Getting last layer's output features\n",
    "\n",
    "model_ft.classifier[1] = nn.Linear(num_ftrs, 2) # Modify the last layer to output 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AX_UoSSKdNWH"
   },
   "source": [
    "## **Initializing optimizers and loss function** <br/>\n",
    "We will also specify the learning rate of the optimiser, here in this case it is set at 0.0001. If our training is bouncing a lot on epochs then we need to decrease the learning rate so that we can reach global minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHp99BjkdaUT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft.to(device)  # Sending model to device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_ft.parameters(), lr=0.000001\n",
    ")  # lr should be kept low so that the pre-trained weights don't change easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtqxKSkrhsui"
   },
   "source": [
    "####**TESTING THE MODEL** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuX_nf-uhsEd"
   },
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    test_loss = []\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if batch_idx == STEPS_PER_TEST_EPOCH:\n",
    "            break\n",
    "\n",
    "        # Model is used to predict the test data so we are switching off the gradient\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.long().to(device)\n",
    "            output = model_ft(data)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Note that optimizer is not used because the model shouldn't learn the test dataset\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                a = []\n",
    "                for j in output[i]:\n",
    "                    a.append(float(j.detach()))\n",
    "\n",
    "                pred = a.index(max(a))\n",
    "\n",
    "                if pred == int(target[i]):\n",
    "                    correct = correct + 1\n",
    "\n",
    "                else:\n",
    "                    incorrect = incorrect + 1\n",
    "\n",
    "        test_loss.append(float(loss.detach()))\n",
    "    print(\"CORRECT: \" + str(correct), \"INCORRECT: \" + str(incorrect),\"TEST ACCURACY: \"+str(correct/(correct+incorrect)))\n",
    "    return (\n",
    "            correct/(incorrect+correct),\n",
    "            sum(test_loss)/len(test_loss),\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "vYDLm1OJ3wNW",
    "outputId": "50419e05-d562-4815-8d45-300f292875c0"
   },
   "outputs": [],
   "source": [
    "acc_ , loss_ = get_test()\n",
    "print(\"ACCURACY AND LOSS BEFORE TUNING\")\n",
    "print(\"ACCURACY : \"+str(acc_),\"LOSS : \"+str(loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3B-9DuF3dz3"
   },
   "source": [
    "####**TUNING THE MODEL (TRAINING)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mmXUZqg13eQu",
    "outputId": "591300ce-3a2f-458a-d5bf-4a99046715e3"
   },
   "outputs": [],
   "source": [
    "avg_test_loss_history = []\n",
    "avg_test_accuracy_history = []\n",
    "avg_train_loss_history = []\n",
    "avg_train_accuracy_history = []\n",
    "\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "new_best = 0\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    start = time.time()\n",
    "    print(\n",
    "        \"-----------------------EPOCH \"\n",
    "        + str(i)\n",
    "        + \" -----------------------------------\"\n",
    "    )\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx == STEPS_PER_EPOCH:\n",
    "            break\n",
    "        optimizer.zero_grad()  # Resetting gradients after each optimizations\n",
    "        # Sending input , target to device\n",
    "        data = data.to(device) \n",
    "        target = target.to(device)\n",
    "        output = model_ft(data)\n",
    "        loss = criterion(output, target.reshape((BATCH_SIZE,)).long())\n",
    "        loss_history.append(loss.detach())\n",
    "        # The loss variable has gradient attached to it so we are removing it so that it can be used to plot graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Optimizing the model\n",
    "\n",
    "        # Checking train accuracy\n",
    "\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        for p in range(BATCH_SIZE):\n",
    "            a = []\n",
    "            for j in output[p]:\n",
    "                a.append(float(j.detach()))\n",
    "\n",
    "            pred = a.index(max(a))\n",
    "\n",
    "            if pred == int(target[p]):\n",
    "                correct = correct + 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                incorrect = incorrect + 1\n",
    "\n",
    "        print(\n",
    "            \"\\r EPOCH \"\n",
    "            + str(i)\n",
    "            + \" MINIBATCH: \"\n",
    "            + str(batch_idx)\n",
    "            + \"/\"\n",
    "            + str(STEPS_PER_EPOCH)\n",
    "            + \" LOSS: \"\n",
    "            + str(loss_history[-1]),\n",
    "            end = \"\"\n",
    "            \n",
    "        )\n",
    "        \n",
    "        accuracy_history.append(correct/(correct+incorrect))\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        \" \\n EPOCH \"\n",
    "        + str(i)\n",
    "        + \" LOSS \"\n",
    "        + str(sum(loss_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\n",
    "        + \" ETA: \"\n",
    "        + str(end - start)\n",
    "        + \" \\n MAX LOSS: \"\n",
    "        + str(max(loss_history[-STEPS_PER_EPOCH:]))\n",
    "        + \" MIN LOSS: \"\n",
    "        + str(min(loss_history[-STEPS_PER_EPOCH:]))\n",
    "        + \" TRAIN ACCURACY: \"\n",
    "        + str(sum(accuracy_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\n",
    "    )\n",
    "    \n",
    "    avg_train_loss_history.append(sum(loss_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\n",
    "    avg_train_accuracy_history.append(sum(accuracy_history[-STEPS_PER_EPOCH:]) / STEPS_PER_EPOCH)\n",
    "    \n",
    "    test_acc , test_loss  = get_test()\n",
    "    \n",
    "    avg_test_accuracy_history.append(test_acc)\n",
    "    avg_train_loss_history.append(test_loss)\n",
    "    \n",
    "    if test_acc>new_best: \n",
    "        new_best = test_acc\n",
    "        torch.save(model_ft.state_dict(), \"_lr0.0001_efficient.pth\") # Saving our best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKPtR_KE4Ps7"
   },
   "source": [
    "#### Plotting the accuracy produced by model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "dFDkHDCT4TAL",
    "outputId": "7864bd8c-7dd8-47bc-ec4c-aaa4e7ce1cba"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_train_accuracy_history , label = \"Train\")\n",
    "plt.plot(avg_test_accuracy_history , label = \"Test\")\n",
    "plt.title('ACCURACY PER EPOCH')\n",
    "plt.xlabel(\"EPOCHS\")\n",
    "plt.ylabel(\"ACCURACY\")\n",
    "plt.legend(loc=\"upper left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('updated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CoronaHack-Finetuning resnet18-pytorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:lipa] *",
   "language": "python",
   "name": "conda-env-lipa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
